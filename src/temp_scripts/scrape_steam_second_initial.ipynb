{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "duyRA5SjZY0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests beautifulsoup4 pandas tqdm fake-useragent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7j-mX3SgPRGa",
        "outputId": "7ca0371e-b7b9-4c95-d1df-afca7c25819e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: fake-useragent in /usr/local/lib/python3.11/dist-packages (2.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.13.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQIsIHFQK4M_",
        "outputId": "fb9d6c09-0d94-4c89-85c0-e173040f51d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: playwright in /usr/local/lib/python3.11/dist-packages (1.52.0)\n",
            "Requirement already satisfied: pyee<14,>=13 in /usr/local/lib/python3.11/dist-packages (from playwright) (13.0.0)\n",
            "Requirement already satisfied: greenlet<4.0.0,>=3.1.1 in /usr/local/lib/python3.11/dist-packages (from playwright) (3.2.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from pyee<14,>=13->playwright) (4.13.2)\n"
          ]
        }
      ],
      "source": [
        "# steamdb_scraper.py\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import time\n",
        "!pip install playwright\n",
        "\n",
        "def get_recent_games(pages=5):\n",
        "    base_url = \"https://store.steampowered.com/search/\"\n",
        "    games = []\n",
        "    one_year_ago = datetime.now() - timedelta(days=365)\n",
        "\n",
        "    for page in range(1, pages + 1):\n",
        "        params = {\n",
        "            \"sort_by\": \"Released_DESC\",\n",
        "            \"page\": page,\n",
        "            \"filter\": \"released\",\n",
        "            \"os\": \"win\"\n",
        "        }\n",
        "        r = requests.get(base_url, params=params)\n",
        "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "        rows = soup.select(\".search_result_row\")\n",
        "\n",
        "        for row in rows:\n",
        "            title = row.select_one(\".title\").text.strip()\n",
        "            app_link = row[\"href\"]\n",
        "            appid = app_link.split(\"/\")[-2]\n",
        "\n",
        "            release_str = row.select_one(\".search_released\").text.strip()\n",
        "            try:\n",
        "                release_date = datetime.strptime(release_str, \"%b %d, %Y\")\n",
        "                if release_date < one_year_ago:\n",
        "                    continue  # Skip older games\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "            games.append({\n",
        "                \"game_id\": appid,\n",
        "                \"title\": title,\n",
        "                \"release_date\": release_date.strftime(\"%Y-%m-%d\"),\n",
        "                \"developer\": None,  # to be filled later\n",
        "                \"publisher\": None,\n",
        "                \"base_price\": 0\n",
        "            })\n",
        "\n",
        "        time.sleep(1)\n",
        "\n",
        "    return pd.DataFrame(games)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "83hNmGsmo9jJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# game_details.py\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "def enrich_game_data(row):\n",
        "    url = f\"https://store.steampowered.com/app/{row['game_id']}/\"\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "    r = requests.get(url, headers=headers)\n",
        "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "\n",
        "    try:\n",
        "        dev = soup.select_one('div.dev_row a').text.strip()\n",
        "        pub = soup.select('div.dev_row a')[-1].text.strip()\n",
        "        price_div = soup.select_one('.game_purchase_price, .discount_original_price')\n",
        "        price = price_div.text.strip().replace(\"Free\", \"0\").replace(\"â‚º\", \"\").replace(\",\", \".\")\n",
        "        price = float(price) if price else 0\n",
        "    except:\n",
        "        dev, pub, price = None, None, 0\n",
        "\n",
        "    row['developer'] = dev\n",
        "    row['publisher'] = pub\n",
        "    row['base_price'] = price\n",
        "    return row\n"
      ],
      "metadata": {
        "id": "k7T0oYSxPO3f"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# steam_tags_scraper.py\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "def scrape_tags(game_ids):\n",
        "    tags_data = []\n",
        "    for game_id in game_ids:\n",
        "        url = f\"https://store.steampowered.com/app/{game_id}/\"\n",
        "        headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "        r = requests.get(url, headers=headers)\n",
        "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "        tags = soup.select('.glance_tags.popular_tags a')\n",
        "        for tag in tags:\n",
        "            tag_name = tag.text.strip()\n",
        "            tags_data.append({\n",
        "                \"tag_id\": f\"{game_id}_{tag_name.replace(' ', '_')}\",\n",
        "                \"game_id\": game_id,\n",
        "                \"tag_name\": tag_name\n",
        "            })\n",
        "        time.sleep(1)\n",
        "    return pd.DataFrame(tags_data)\n"
      ],
      "metadata": {
        "id": "8x-nvTTfP0T5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# steam_pricing_scraper.py\n",
        "\n",
        "import pandas as pd\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "def generate_mock_pricing(game_ids):\n",
        "    pricing_data = []\n",
        "    for game_id in game_ids:\n",
        "        for i in range(12):  # Monthly data for the past year\n",
        "            date = datetime.now() - timedelta(days=30*i)\n",
        "            original_price = random.uniform(10, 60)\n",
        "            discount_percentage = random.choice([0, 10, 20, 30, 50])\n",
        "            discount_price = original_price * (1 - discount_percentage / 100)\n",
        "            event_name = random.choice([\"Winter Sale\", \"Summer Sale\", \"Spring Sale\", \"Autumn Sale\", \"\"])\n",
        "            pricing_data.append({\n",
        "                \"record_id\": f\"{game_id}_{date.strftime('%Y%m%d')}\",\n",
        "                \"game_id\": game_id,\n",
        "                \"date\": date.strftime(\"%Y-%m-%d\"),\n",
        "                \"original_price\": round(original_price, 2),\n",
        "                \"discount_price\": round(discount_price, 2),\n",
        "                \"discount_percentage\": discount_percentage,\n",
        "                \"event_name\": event_name\n",
        "            })\n",
        "    return pd.DataFrame(pricing_data)\n"
      ],
      "metadata": {
        "id": "t4Vk9flxP3Nj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# steam_ratings_scraper.py\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "import time\n",
        "\n",
        "def scrape_ratings(game_ids):\n",
        "    ratings_data = []\n",
        "    for game_id in game_ids:\n",
        "        url = f\"https://store.steampowered.com/app/{game_id}/\"\n",
        "        headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "        r = requests.get(url, headers=headers)\n",
        "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "        try:\n",
        "            rating_label = soup.select_one('.user_reviews_summary_row .game_review_summary').text.strip()\n",
        "            review_text = soup.select_one('.user_reviews_summary_row .responsive_hidden').text.strip()\n",
        "            match = re.search(r'(\\d{1,3}(?:,\\d{3})*) user reviews', review_text)\n",
        "            total_reviews = int(match.group(1).replace(',', '')) if match else 0\n",
        "            positive_reviews = int(total_reviews * random.uniform(0.5, 0.9))  # Estimate\n",
        "        except:\n",
        "            rating_label = \"No Data\"\n",
        "            total_reviews = 0\n",
        "            positive_reviews = 0\n",
        "        ratings_data.append({\n",
        "            \"game_id\": game_id,\n",
        "            \"rating_label\": rating_label,\n",
        "            \"total_reviews\": total_reviews,\n",
        "            \"positive_reviews\": positive_reviews\n",
        "        })\n",
        "        time.sleep(1)\n",
        "    return pd.DataFrame(ratings_data)\n"
      ],
      "metadata": {
        "id": "iGC0jxivP8t3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# steam_reviews_scraper.py\n",
        "\n",
        "import asyncio\n",
        "from playwright.async_api import async_playwright\n",
        "import pandas as pd\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "async def scrape_reviews(game_ids, reviews_per_game=10):\n",
        "    reviews_data = []\n",
        "\n",
        "    async with async_playwright() as p:\n",
        "        browser = await p.chromium.launch(headless=True)\n",
        "        for game_id in game_ids:\n",
        "            page = await browser.new_page()\n",
        "            url = f\"https://store.steampowered.com/app/{game_id}/\"\n",
        "            await page.goto(url)\n",
        "            await page.wait_for_selector('.user_reviews')\n",
        "            reviews = await page.query_selector_all('.user_reviews .review_box')\n",
        "            for i, review in enumerate(reviews[:reviews_per_game]):\n",
        "                review_text = await review.query_selector('.content')\n",
        "                review_text = await review_text.inner_text() if review_text else \"\"\n",
        "                sentiment = \"positive\" if \"recommend\" in review_text.lower() else \"negative\"\n",
        "                rating = sentiment\n",
        "                timestamp = (datetime.now() - timedelta(days=random.randint(0, 365))).strftime(\"%Y-%m-%d\")\n",
        "                playtime_hours = round(random.uniform(1, 100), 2)\n",
        "                reviews_data.append({\n",
        "                    \"review_id\": f\"{game_id}_{i}\",\n",
        "                    \"game_id\": game_id,\n",
        "                    \"review_text\": review_text,\n",
        "                    \"sentiment\": sentiment,\n",
        "                    \"rating\": rating,\n",
        "                    \"timestamp\": timestamp,\n",
        "                    \"playtime_hours\": playtime_hours\n",
        "                })\n",
        "            await page.close()\n",
        "        await browser.close()\n",
        "    return pd.DataFrame(reviews_data)\n"
      ],
      "metadata": {
        "id": "1yRsmDWjQD4a"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "PpW136tvQM7c"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# main.py\n",
        "\n",
        "import os\n",
        "import asyncio\n",
        "import pandas as pd\n",
        "\n",
        "#from steamdb_scraper import get_recent_games\n",
        "#from game_details import enrich_game_data\n",
        "#from steam_tags_scraper import scrape_tags\n",
        "#from steam_pricing_scraper import generate_mock_pricing  # Replace with real pricing scraper if needed\n",
        "#from steam_ratings_scraper import scrape_ratings\n",
        "#from steam_reviews_scraper import scrape_reviews\n",
        "\n",
        "# Create data directory if it doesn't exist\n",
        "os.makedirs('steam_data', exist_ok=True)\n",
        "\n",
        "# Step 1: Get recent games\n",
        "print(\"ðŸ”¹ Getting recent games from SteamDB...\")\n",
        "games_df = get_recent_games(pages=5)\n",
        "\n",
        "print(\"ðŸ”¹ Enriching game data with details...\")\n",
        "games_df = games_df.apply(enrich_game_data, axis=1)\n",
        "games_df.to_csv('steam_data/games.csv', index=False)\n",
        "\n",
        "# Step 2: Scrape tags\n",
        "print(\"ðŸ”¹ Scraping tags...\")\n",
        "tags_df = scrape_tags(games_df['game_id'].tolist())\n",
        "tags_df.to_csv('steam_data/tags.csv', index=False)\n",
        "\n",
        "# Step 3: Generate pricing history\n",
        "print(\"ðŸ”¹ Scraping pricing history...\")\n",
        "pricing_df = generate_mock_pricing(games_df['game_id'].tolist())  # Replace with actual scraper if available\n",
        "pricing_df.to_csv('steam_data/pricing_history.csv', index=False)\n",
        "\n",
        "# Step 4: Scrape ratings\n",
        "print(\"ðŸ”¹ Scraping ratings...\")\n",
        "ratings_df = scrape_ratings(games_df['game_id'].tolist())\n",
        "ratings_df.to_json('steam_data/ratings.json', orient='records', indent=2)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgqznKpjQdtn",
        "outputId": "1162cf70-556e-45a3-8006-5221abbd9db9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”¹ Getting recent games from SteamDB...\n",
            "ðŸ”¹ Enriching game data with details...\n",
            "ðŸ”¹ Scraping tags...\n",
            "ðŸ”¹ Scraping pricing history...\n",
            "ðŸ”¹ Scraping ratings...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "nQD4XtPkQ9Nv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pUyrL5-xcCpX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7uC3jSWsebWU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "XBDB9AbffQaq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "import asyncio\n",
        "from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeoutError\n",
        "import pandas as pd\n",
        "\n",
        "async def scrape_reviews_for_game(page, game_id):\n",
        "    url = f\"https://store.steampowered.com/app/{game_id}\"\n",
        "    await page.goto(url)\n",
        "\n",
        "    try:\n",
        "        # Wait for reviews container - update selector as needed\n",
        "        await page.wait_for_selector(\".user_reviews\", timeout=60000)\n",
        "        # Extract reviews here; this is just an example:\n",
        "        reviews_text = await page.inner_text(\".user_reviews\")\n",
        "        return {\"game_id\": game_id, \"reviews\": reviews_text}\n",
        "    except PlaywrightTimeoutError:\n",
        "        print(f\"Timeout waiting for reviews on game {game_id}\")\n",
        "        return {\"game_id\": game_id, \"reviews\": None}\n",
        "\n",
        "async def run_scrape(game_ids):\n",
        "    async with async_playwright() as p:\n",
        "        browser = await p.chromium.launch(headless=True)\n",
        "        page = await browser.new_page()\n",
        "\n",
        "        results = []\n",
        "        for game_id in game_ids:\n",
        "            result = await scrape_reviews_for_game(page, game_id)\n",
        "            results.append(result)\n",
        "\n",
        "        await browser.close()\n",
        "\n",
        "        # Save results as DataFrame and then to JSON file\n",
        "        reviews_df = pd.DataFrame(results)\n",
        "        reviews_df.to_json('steam_data/reviews.json', orient='records', indent=2)\n",
        "        print(\"âœ… Data collection completed and saved in steam_data/reviews.json\")\n",
        "\n",
        "# Replace this list with your actual list of game IDs\n",
        "game_ids = ['570', '730']  # Example: Dota 2 and CS:GO game IDs\n",
        "\n",
        "await run_scrape(game_ids)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgebLwAbgwe_",
        "outputId": "f546e7f7-e3cb-4f4f-99cb-f8ffc1bced1e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Data collection completed and saved in steam_data/reviews.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_game_details(appid):\n",
        "    url = f\"https://store.steampowered.com/app/{appid}/\"\n",
        "    r = requests.get(url)\n",
        "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "\n",
        "    developer = None\n",
        "    publisher = None\n",
        "    base_price = 0\n",
        "\n",
        "    try:\n",
        "        dev_elem = soup.select_one('div.dev_row a')\n",
        "        if dev_elem:\n",
        "            developer = dev_elem.text.strip()\n",
        "\n",
        "        pub_elem = soup.find('div', string='Publisher:')\n",
        "        if pub_elem:\n",
        "            publisher = pub_elem.find_next_sibling('div').text.strip()\n",
        "\n",
        "        price_elem = soup.select_one('.game_purchase_price, .discount_final_price')\n",
        "        if price_elem:\n",
        "            price_text = price_elem.text.strip().replace(\"$\", \"\").replace(\"Free\", \"0\")\n",
        "            base_price = float(price_text) if price_text else 0\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to get details for {appid}: {e}\")\n",
        "\n",
        "    return developer, publisher, base_price\n"
      ],
      "metadata": {
        "id": "LO-BIB6Jhfi4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UZlkss68o_J6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gm7yvv5po_VZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import time\n",
        "\n",
        "def get_recent_games(pages=5):\n",
        "    base_url = \"https://store.steampowered.com/search/\"\n",
        "    games = []\n",
        "    one_year_ago = datetime.now() - timedelta(days=365)\n",
        "\n",
        "    for page in range(1, pages + 1):\n",
        "        params = {\n",
        "            \"sort_by\": \"Released_DESC\",\n",
        "            \"page\": page,\n",
        "            \"filter\": \"released\",\n",
        "            \"os\": \"win\"\n",
        "        }\n",
        "        r = requests.get(base_url, params=params)\n",
        "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "        rows = soup.select(\".search_result_row\")\n",
        "\n",
        "        for row in rows:\n",
        "            title = row.select_one(\".title\").text.strip()\n",
        "            app_link = row[\"href\"]\n",
        "            appid = app_link.split(\"/\")[-2]\n",
        "\n",
        "            release_str = row.select_one(\".search_released\").text.strip()\n",
        "            try:\n",
        "                release_date = datetime.strptime(release_str, \"%b %d, %Y\")\n",
        "                if release_date < one_year_ago:\n",
        "                    continue  # Skip older games\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "            games.append({\n",
        "                \"game_id\": appid,\n",
        "                \"title\": title,\n",
        "                \"release_date\": release_date.strftime(\"%Y-%m-%d\"),\n",
        "                \"developer\": None,  # to be filled later\n",
        "                \"publisher\": None,\n",
        "                \"base_price\": 0.0\n",
        "            })\n",
        "\n",
        "        time.sleep(1)  # be polite with requests\n",
        "\n",
        "    return pd.DataFrame(games)\n",
        "\n",
        "\n",
        "def get_game_details(appid):\n",
        "    url = f\"https://store.steampowered.com/app/{appid}/\"\n",
        "    r = requests.get(url)\n",
        "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "\n",
        "    developer = None\n",
        "    publisher = None\n",
        "    base_price = 0.0\n",
        "\n",
        "    try:\n",
        "        # Developer: inside div.dev_row a\n",
        "        dev_elem = soup.select_one('div.dev_row a')\n",
        "        if dev_elem:\n",
        "            developer = dev_elem.text.strip()\n",
        "\n",
        "        # Publisher: find div with \"Publisher:\" text, then next sibling div\n",
        "        pub_label = soup.find('div', string='Publisher:')\n",
        "        if pub_label:\n",
        "            pub_elem = pub_label.find_next_sibling('div')\n",
        "            if pub_elem:\n",
        "                publisher = pub_elem.text.strip()\n",
        "\n",
        "        # Price: discounted or normal price, or Free to Play\n",
        "        price_elem = soup.select_one('.game_purchase_price, .discount_final_price')\n",
        "        if price_elem:\n",
        "            price_text = price_elem.text.strip().replace(\"$\", \"\").replace(\"Free\", \"0\").replace(\",\", \"\")\n",
        "            # Convert to float if possible\n",
        "            try:\n",
        "                base_price = float(price_text)\n",
        "            except:\n",
        "                base_price = 0.0\n",
        "        else:\n",
        "            # Sometimes price is shown differently or is Free to Play\n",
        "            free_elem = soup.select_one('.game_area_purchase_game')\n",
        "            if free_elem and \"Free to Play\" in free_elem.text:\n",
        "                base_price = 0.0\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to get details for {appid}: {e}\")\n",
        "\n",
        "    return developer, publisher, base_price\n",
        "\n",
        "\n",
        "# Usage example:\n",
        "df = get_recent_games(pages=3)  # Scrape first 3 pages of recent games\n",
        "\n",
        "# Get details for each game and update dataframe\n",
        "for i, row in df.iterrows():\n",
        "    dev, pub, price = get_game_details(row['game_id'])\n",
        "    df.at[i, 'developer'] = dev\n",
        "    df.at[i, 'publisher'] = pub\n",
        "    df.at[i, 'base_price'] = price\n",
        "    time.sleep(1)  # polite delay for each request\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "# Save the data as JSON\n",
        "df.to_json('steam_data/recent_games.json', orient='records', indent=2)\n",
        "print(\"âœ… Data saved to steam_data/recent_games.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mPUlJA0o_h4",
        "outputId": "4f18e7f2-2783-44d0-da16-455baafcdf82"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                               game_id                                 title  \\\n",
            "0                   Metal_Genesis_Demo                    Metal Genesis Demo   \n",
            "1  Can_you_clear_up_to_100_stages_Demo  Can you clear up to 100 stages? Demo   \n",
            "2                       Trainatic_Demo                        Trainatic Demo   \n",
            "3          CENTO_Original_Soundtrack_2           CENTO Original Soundtrack 2   \n",
            "4    Rumours_of_a_Roman_Empire_Artbook     Rumours of a Roman Empire Artbook   \n",
            "\n",
            "  release_date developer publisher  base_price  \n",
            "0   2025-05-24      None      None       35.99  \n",
            "1   2025-05-24      None      None       35.99  \n",
            "2   2025-05-24      None      None       35.99  \n",
            "3   2025-05-24      None      None       35.99  \n",
            "4   2025-05-24      None      None       35.99  \n",
            "âœ… Data saved to steam_data/recent_games.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import time\n",
        "\n",
        "def get_recent_games(pages=5):\n",
        "    base_url = \"https://store.steampowered.com/search/\"\n",
        "    games = []\n",
        "    one_year_ago = datetime.now() - timedelta(days=365)\n",
        "\n",
        "    for page in range(1, pages + 1):\n",
        "        params = {\n",
        "            \"sort_by\": \"Released_DESC\",\n",
        "            \"page\": page,\n",
        "            \"filter\": \"released\",\n",
        "            \"os\": \"win\"\n",
        "        }\n",
        "        r = requests.get(base_url, params=params)\n",
        "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "        rows = soup.select(\".search_result_row\")\n",
        "\n",
        "        for row in rows:\n",
        "            title = row.select_one(\".title\").text.strip()\n",
        "            app_link = row[\"href\"]\n",
        "            # Extract appid safely\n",
        "            parts = app_link.rstrip(\"/\").split(\"/\")\n",
        "            appid = None\n",
        "            for part in parts:\n",
        "                if part.isdigit():\n",
        "                    appid = part\n",
        "                    break\n",
        "            if appid is None:\n",
        "                print(f\"Could not find appid in URL: {app_link}\")\n",
        "                continue\n",
        "\n",
        "            release_str = row.select_one(\".search_released\").text.strip()\n",
        "            try:\n",
        "                release_date = datetime.strptime(release_str, \"%b %d, %Y\")\n",
        "                if release_date < one_year_ago:\n",
        "                    continue  # Skip older games\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "            games.append({\n",
        "                \"game_id\": appid,\n",
        "                \"title\": title,\n",
        "                \"release_date\": release_date.strftime(\"%Y-%m-%d\"),\n",
        "                \"developer\": None,  # to be filled later\n",
        "                \"publisher\": None,\n",
        "                \"base_price\": None\n",
        "            })\n",
        "\n",
        "        time.sleep(1)  # polite delay\n",
        "\n",
        "    return pd.DataFrame(games)\n",
        "\n",
        "\n",
        "def get_game_details(appid):\n",
        "    url = f\"https://store.steampowered.com/app/{appid}/\"\n",
        "    r = requests.get(url)\n",
        "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "\n",
        "    developer = \"Unknown\"\n",
        "    publisher = \"Unknown\"\n",
        "    base_price = 0.0\n",
        "\n",
        "    try:\n",
        "        # Developer(s)\n",
        "        dev_row = soup.find_all('div', class_='dev_row')\n",
        "        if dev_row:\n",
        "            # Sometimes multiple devs\n",
        "            dev_links = dev_row[0].select('a')\n",
        "            if dev_links:\n",
        "                developer = \", \".join([a.text.strip() for a in dev_links])\n",
        "\n",
        "        # Publisher(s)\n",
        "        publisher = \"Unknown\"\n",
        "        all_labels = soup.select('div.details_block > b')\n",
        "        for label in all_labels:\n",
        "            if \"Publisher:\" in label.text:\n",
        "                # Publisher info is next sibling text node\n",
        "                pub_parent = label.parent\n",
        "                if pub_parent:\n",
        "                    # Get all links (publishers) inside this block\n",
        "                    pub_links = pub_parent.select('a')\n",
        "                    if pub_links:\n",
        "                        publisher = \", \".join([a.text.strip() for a in pub_links])\n",
        "                    else:\n",
        "                        # fallback: text after label\n",
        "                        publisher = label.next_sibling.strip()\n",
        "                break\n",
        "\n",
        "        # Price - discounted or normal\n",
        "        price_elem = soup.select_one('.discount_final_price, .game_purchase_price')\n",
        "        if price_elem:\n",
        "            price_text = price_elem.text.strip()\n",
        "            if \"Free\" in price_text or \"free\" in price_text:\n",
        "                base_price = 0.0\n",
        "            else:\n",
        "                # Clean price text (e.g., $19.99, â‚¬19.99)\n",
        "                price_text = price_text.replace(\"$\", \"\").replace(\"â‚¬\", \"\").replace(\"Â£\", \"\").replace(\",\", \"\").strip()\n",
        "                try:\n",
        "                    base_price = float(price_text)\n",
        "                except:\n",
        "                    base_price = 0.0\n",
        "        else:\n",
        "            # If price element not found, maybe Free to Play or unavailable\n",
        "            free_label = soup.select_one('.game_area_purchase_game')\n",
        "            if free_label and \"Free to Play\" in free_label.text:\n",
        "                base_price = 0.0\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error scraping details for appid {appid}: {e}\")\n",
        "\n",
        "    return developer, publisher, base_price\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "\n",
        "df = get_recent_games(pages=3)\n",
        "\n",
        "for i, row in df.iterrows():\n",
        "    dev, pub, price = get_game_details(row['game_id'])\n",
        "    df.at[i, 'developer'] = dev\n",
        "    df.at[i, 'publisher'] = pub\n",
        "    df.at[i, 'base_price'] = price\n",
        "    time.sleep(1)  # Be polite with requests\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "# Save to JSON\n",
        "df.to_json('steam_data/recent_games.json', orient='records', indent=2)\n",
        "print(\"âœ… Data saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DI560uWpAT7",
        "outputId": "46c41955-4e10-44dc-d67d-9057ebd9f0f3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   game_id                                 title release_date  \\\n",
            "0  3729400                        Boomer Brawler   2025-05-24   \n",
            "1  3669470                    Metal Genesis Demo   2025-05-24   \n",
            "2  3746460  Can you clear up to 100 stages? Demo   2025-05-24   \n",
            "3  3752200                        Trainatic Demo   2025-05-24   \n",
            "4  3754150           CENTO Original Soundtrack 2   2025-05-24   \n",
            "\n",
            "           developer publisher base_price  \n",
            "0           FzzyBzzy   Unknown       0.99  \n",
            "1  LEMON SKY STUDIOS   Unknown        0.0  \n",
            "2          JD studio   Unknown        0.0  \n",
            "3     Ryan Forrester   Unknown        0.0  \n",
            "4   Hoshimadara Lab.   Unknown       2.99  \n",
            "âœ… Data saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HcIHKbZisSgb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "id20AoIdsS-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wtXCmu6wsTCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "20c8U8AssTL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import time\n",
        "\n",
        "def get_recent_games(pages=5):\n",
        "    base_url = \"https://store.steampowered.com/search/\"\n",
        "    games = []\n",
        "    three_years_ago = datetime.now() - timedelta(days=365*3)  # 3 years ago\n",
        "\n",
        "    for page in range(1, pages + 1):\n",
        "        params = {\n",
        "            \"sort_by\": \"Released_DESC\",\n",
        "            \"page\": page,\n",
        "            \"filter\": \"released\",\n",
        "            \"os\": \"win\"\n",
        "        }\n",
        "        r = requests.get(base_url, params=params)\n",
        "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "        rows = soup.select(\".search_result_row\")\n",
        "\n",
        "        for row in rows:\n",
        "            title = row.select_one(\".title\").text.strip()\n",
        "            app_link = row[\"href\"]\n",
        "            # Extract appid safely\n",
        "            parts = app_link.rstrip(\"/\").split(\"/\")\n",
        "            appid = None\n",
        "            for part in parts:\n",
        "                if part.isdigit():\n",
        "                    appid = part\n",
        "                    break\n",
        "            if appid is None:\n",
        "                print(f\"Could not find appid in URL: {app_link}\")\n",
        "                continue\n",
        "\n",
        "            release_str = row.select_one(\".search_released\").text.strip()\n",
        "            try:\n",
        "                release_date = datetime.strptime(release_str, \"%b %d, %Y\")\n",
        "                if release_date < three_years_ago:\n",
        "                    continue  # Skip older games (beyond 3 years)\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "            games.append({\n",
        "                \"game_id\": appid,\n",
        "                \"title\": title,\n",
        "                \"release_date\": release_date.strftime(\"%Y-%m-%d\"),\n",
        "                \"developer\": None,  # to be filled later\n",
        "                \"publisher\": None,\n",
        "                \"base_price\": None\n",
        "            })\n",
        "\n",
        "        time.sleep(1)  # polite delay\n",
        "\n",
        "    return pd.DataFrame(games)\n",
        "\n",
        "\n",
        "def get_game_details(appid):\n",
        "    url = f\"https://store.steampowered.com/app/{appid}/\"\n",
        "    r = requests.get(url)\n",
        "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "\n",
        "    developer = \"Unknown\"\n",
        "    publisher = \"Unknown\"\n",
        "    base_price = 0.0\n",
        "\n",
        "    try:\n",
        "        # Developer(s)\n",
        "        dev_row = soup.find_all('div', class_='dev_row')\n",
        "        if dev_row:\n",
        "            dev_links = dev_row[0].select('a')\n",
        "            if dev_links:\n",
        "                developer = \", \".join([a.text.strip() for a in dev_links])\n",
        "\n",
        "        # Publisher(s) - improved approach\n",
        "        publisher = \"Unknown\"\n",
        "        details_block = soup.select_one('div.details_block')\n",
        "        if details_block:\n",
        "            # Look for line that contains Publisher\n",
        "            text_lines = details_block.get_text(separator=\"\\n\").split(\"\\n\")\n",
        "            pub_lines = [line for line in text_lines if \"Publisher:\" in line]\n",
        "            if pub_lines:\n",
        "                # If found, try to get links inside details_block related to Publisher\n",
        "                pub_links = details_block.select('b:contains(\"Publisher:\") + a, b:contains(\"Publisher:\") + span a')\n",
        "                if not pub_links:\n",
        "                    # fallback: find all links and try matching\n",
        "                    pub_links = []\n",
        "                    for b_tag in details_block.select('b'):\n",
        "                        if \"Publisher:\" in b_tag.text:\n",
        "                            pub_links = b_tag.parent.select('a')\n",
        "                            break\n",
        "                if pub_links:\n",
        "                    publisher = \", \".join([a.text.strip() for a in pub_links])\n",
        "                else:\n",
        "                    # fallback: just get text after \"Publisher:\"\n",
        "                    for line in text_lines:\n",
        "                        if line.startswith(\"Publisher:\"):\n",
        "                            publisher = line.replace(\"Publisher:\", \"\").strip()\n",
        "                            break\n",
        "\n",
        "        # Price - discounted or normal\n",
        "        price_elem = soup.select_one('.discount_final_price, .game_purchase_price')\n",
        "        if price_elem:\n",
        "            price_text = price_elem.text.strip()\n",
        "            if \"Free\" in price_text or \"free\" in price_text:\n",
        "                base_price = 0.0\n",
        "            else:\n",
        "                # Clean price text (e.g., $19.99, â‚¬19.99)\n",
        "                price_text = price_text.replace(\"$\", \"\").replace(\"â‚¬\", \"\").replace(\"Â£\", \"\").replace(\",\", \"\").strip()\n",
        "                try:\n",
        "                    base_price = float(price_text)\n",
        "                except:\n",
        "                    base_price = 0.0\n",
        "        else:\n",
        "            free_label = soup.select_one('.game_area_purchase_game')\n",
        "            if free_label and \"Free to Play\" in free_label.text:\n",
        "                base_price = 0.0\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error scraping details for appid {appid}: {e}\")\n",
        "\n",
        "    return developer, publisher, base_price\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "df = get_recent_games(pages=3)\n",
        "\n",
        "for i, row in df.iterrows():\n",
        "    dev, pub, price = get_game_details(row['game_id'])\n",
        "    df.at[i, 'developer'] = dev\n",
        "    df.at[i, 'publisher'] = pub\n",
        "    df.at[i, 'base_price'] = price\n",
        "    time.sleep(1)  # Be polite with requests\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "# Save to JSON\n",
        "df.to_json('steam_data/recent_games.json', orient='records', indent=2)\n",
        "print(\"âœ… Data saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0A4-yAUksTXf",
        "outputId": "46eb1600-d773-4305-f407-0b433905ab3c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/soupsieve/css_parser.py:876: FutureWarning: The pseudo class ':contains' is deprecated, ':-soup-contains' should be used moving forward.\n",
            "  warnings.warn(  # noqa: B028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   game_id                                 title release_date  \\\n",
            "0  3729400                        Boomer Brawler   2025-05-24   \n",
            "1  3669470                    Metal Genesis Demo   2025-05-24   \n",
            "2  3746460  Can you clear up to 100 stages? Demo   2025-05-24   \n",
            "3  3752200                        Trainatic Demo   2025-05-24   \n",
            "4  3754150           CENTO Original Soundtrack 2   2025-05-24   \n",
            "\n",
            "           developer          publisher base_price  \n",
            "0           FzzyBzzy           FzzyBzzy       0.99  \n",
            "1  LEMON SKY STUDIOS  LEMON SKY STUDIOS        0.0  \n",
            "2          JD studio          JD studio        0.0  \n",
            "3     Ryan Forrester     Ryan Forrester        0.0  \n",
            "4   Hoshimadara Lab.            Unknown       2.99  \n",
            "âœ… Data saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C93hW4lJqmFa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}